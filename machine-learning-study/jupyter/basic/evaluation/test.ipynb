{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータによる評価\n",
    "\n",
    "## 評価(test)<a name=\"test\"></a>\n",
    "\n",
    "- 過学習した状態で機械学習プロダクトを本番環境にデプロイすると痛い目を見るので、モデルが過学習していないかを評価するのは重要\n",
    "- 評価には通常、訓練データとは別のテストデータを用意して、訓練済みモデルを適用する\n",
    "- 一貫した評価のため、テストデータには評価する対象のモデル間で毎回同じデータセットを用いる\n",
    "- テストデータに偏りがあると正しい評価ができないため、慎重に設計する必要がある\n",
    "- データセットを訓練データとテストデータで6:4、7:3、8:2のいずれかで分割して使用するのが一般的\n",
    "- データセットが十分に大きい場合は、9:1や99:1も用いられる\n",
    "\n",
    "## 精度による評価<a name=\"accuracy\"></a>\n",
    "\n",
    "分類問題の場合、精度(正解率)が最も単純な評価指標。\n",
    "\n",
    "### テストデータの作成<a name=\"accuracy_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loader = load_breast_cancer()\n",
    "X, y = loader.data, loader.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価実行<a name=\"accuracy_test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print('Train accuracy: {train:.3f}, Test accuracy: {test:.3f}'.format(train=train_score, test=test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差による評価<a name=\"error\"></a>\n",
    "\n",
    "回帰問題の場合、精度では評価できない。予測値と正解の誤差が最も単純な評価指標だが、外れ値の影響を受けやすい。\n",
    "\n",
    "### テストデータの作成<a name=\"error_test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "loader = load_diabetes()\n",
    "X, y = loader.data, loader.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習<a name=\"error_training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二乗平均平方根(Root Mean Square, RMS)<a name=\"root_mean_square\"></a>\n",
    "\n",
    "回帰に通常使われる平均二乗誤差の場合、その平方根が目安になる。平均二乗誤差については[別の項](../optimization/optimization.ipynb#mean_squared_error)で説明する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_score = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "test_score = np.sqrt(mean_squared_error(y_test, test_pred))\n",
    "print('Train RMS: {train:.3f}, Test RMS: {test:.3f}'.format(train=train_score, test=test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差のプロット<a name=\"error_plot\"></a>\n",
    "\n",
    "誤差(残差)をプロットしてみて、正解の周辺にランダムに予測値が分布しているのが理想的。誤差に規則性がある場合は、何らかの特徴を補足しきれていない可能性がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_residual = train_pred - y_train\n",
    "test_residual = test_pred - y_test\n",
    "all_pred = np.concatenate((train_pred, test_pred), axis=0)\n",
    "all_residual = np.concatenate((train_residual, test_residual), axis=0)\n",
    "margin = 10\n",
    "x_min, x_max = all_pred.min() - margin, all_pred.max() + margin\n",
    "y_min, y_max = all_residual.min() - margin, all_residual.max() + margin\n",
    "\n",
    "plt.scatter(train_pred, train_pred - y_train, c='blue', label='Train')\n",
    "plt.scatter(test_pred, test_pred - y_test, c='red', label='Test')\n",
    "plt.hlines(y=0, xmin=x_min, xmax=x_max, color='green')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Residual')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 決定係数による評価<a name=\"r2\"></a>\n",
    "\n",
    "回帰問題へのモデルの適合度を表す指標として、決定係数$R^2$がある。$R^2$は、正解データの分散をどれくらい補足できているかの割合を示す。モデルの性能があまりに悪いと、負の値も取りうる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "train_r2 = r2_score(y_train, train_pred)\n",
    "test_r2 = r2_score(y_test, test_pred)\n",
    "print('Train R^2: {train:.2f}, Test R^2: {test:.2f}'.format(train=train_r2, test=test_r2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
