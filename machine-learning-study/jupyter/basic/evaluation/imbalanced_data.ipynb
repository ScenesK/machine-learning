{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不均衡データの評価\n",
    "\n",
    "## 不均衡データとは<a name=\"description\"></a>\n",
    "\n",
    "$A:B=1:99$ などクラス間のサンプル数に極端な偏りのあるデータ。$A$を無視して全て$B$と予測するモデルでも精度99%を達成してしまう。精度をモデルの評価指標とできないので、他の指標が必要。\n",
    "\n",
    "不均衡データを評価するには、まず混同行列を理解しないといけない。\n",
    "\n",
    "### 混同行列(confusion matrix)<a name=\"confusion_matrix\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loader = load_breast_cancer()\n",
    "X, y = loader.data, loader.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0, stratify=y)\n",
    "y_pred = LogisticRegression(random_state=0, n_jobs=-1).fit(X_train, y_train).predict(X_test)\n",
    "labels, labels_str = [1, 0], ['1 (True)', '0 (False)']\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=labels)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax1, ax2 = axes[0], axes[1]\n",
    "\n",
    "ax1.matshow(np.zeros((2, 2)), alpha=0)\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        value = 'True ' if row == col else 'False '\n",
    "        value += 'Positive' if col == 0 else 'Negative'\n",
    "        ax1.text(x=col, y=row, s=value, va='center', ha='center')\n",
    "\n",
    "ax2.matshow(confmat, alpha=.3)\n",
    "for row, cols in enumerate(confmat):\n",
    "    for col, value in enumerate(cols):\n",
    "        ax2.text(x=col, y=row, s=value, va='center', ha='center')\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('true label')\n",
    "        ax.set_yticks([0, 1])\n",
    "        ax.set_yticks([.5], minor=True)\n",
    "        ax.set_yticklabels(labels_str)\n",
    "    else:\n",
    "        ax.set_yticklabels(())\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('predicted')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticks([.5], minor=True)\n",
    "    ax.set_xticklabels(labels_str)\n",
    "    ax.grid(linestyle='-', which='minor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 適合率(precision)・再現率(recall)・F1スコア<a name=\"f1\"></a>\n",
    "\n",
    "適合率(precision)とは、Trueと分類したものの中での正解率\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "    PRE=\\frac{TP}{TP+FP} \\nonumber\n",
    "\\end{eqnarray}$\n",
    "\n",
    "再現率(recall)とは、正解ラベルがTrueのものの中での正解率\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "    REC=\\frac{TP}{TP+FN} \\nonumber\n",
    "\\end{eqnarray}$\n",
    "\n",
    "F1スコアとは、適合率と再現率を組み合わせた指標。適合率・再現率ともに高くないと値が大きくならない。\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "    F1=2\\times\\frac{PRE\\times REC}{PRE+REC} \\nonumber\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "division = 10\n",
    "values = np.linspace(.1, 1, division)\n",
    "\n",
    "M = np.zeros((division, division, 2))\n",
    "for i, v in enumerate(values):\n",
    "    M[:, i, 0] = v\n",
    "    M[i, :, 1] = v\n",
    "PRE, REC = M[:, :, 0], M[:, :, 1]\n",
    "F1 = 2 * (PRE * REC) / (PRE + REC)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_title('F1 score')\n",
    "\n",
    "ax.matshow(F1, cmap='Reds', alpha=.6)\n",
    "for row, cols in enumerate(F1):\n",
    "    for col, value in enumerate(cols):\n",
    "        ax.text(x=col, y=row, s='%.2f' % value, va='center', ha='center', size='x-small')\n",
    "\n",
    "ticks = np.arange(division)\n",
    "ticklabels = ['%.1f' % v for v in values]\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels(ticklabels, size='x-small')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(ticklabels, size='x-small')\n",
    "ax.set_ylabel('Precision')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 受信者操作特性(Reciever Operator Characteristic, ROC)<a name=\"roc\"></a>\n",
    "\n",
    "真陽性率(True Positive Rate)と偽陽性率(False Positve Rate)に基づく指標。\n",
    "\n",
    "真陽性率とは、正解ラベルがTrueのものの中での正解率。\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "TPR=\\frac{TP}{TP+FN} \\nonumber\n",
    "\\end{eqnarray}$\n",
    "\n",
    "偽陽性率とは、正解ラベルがFalseのものの中での不正解率。\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "    FPR\\ =\\ \\frac{FP}{FP+TN} \\nonumber\n",
    "\\end{eqnarray}$\n",
    "\n",
    "通常、分類器の出力が0.5以上ならTrue・0.5未満ならFalseと予測するが、この閾値を変化させた場合のTPR・FPRの変化を描画したものがROC曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 50)\n",
    "roc = np.sqrt(1 - (x - 1) ** 2)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title('Receiver Operator Characteristic Curve')\n",
    "\n",
    "plt.fill_between(x, 0, roc, alpha=.1)\n",
    "plt.plot(x, roc, label='ROC')\n",
    "plt.plot([0, 0, 1], [0, 1, 1], linestyle='--', label='Perfect performance')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Random guessing')\n",
    "\n",
    "plt.legend(loc='lower right', fontsize='small')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim(-.05, 1.05)\n",
    "plt.ylim(-.05, 1.05)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフの四隅は\n",
    "\n",
    "- 左上…TPR=1, FPR=0→全てのサンプルで分類成功\n",
    "- 左下…TPR=0, FPR=0→全てのサンプルをFalseと予測\n",
    "- 右上…TPR=1, FPR=1→全てのサンプルをTrueと予測\n",
    "- 右下…TPR=0, FPR=1→全てのサンプルで分類失敗\n",
    "\n",
    "を表す。\n",
    "\n",
    "ROC曲線の下部分の面積(Area Under the Curve, AUC)を、その分類器の性能と捉えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "model = LogisticRegression(random_state=0, n_jobs=-1).fit(X_train[:, -2:], y_train)\n",
    "probas = model.predict_proba(X_test[:, -2:])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas[:, 1], pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "pred = model.predict(X_test[:, -2:])\n",
    "print('ROC AUC: {roc:.3f}, Accuracy: {acc:.3f}'.format(\n",
    "    roc=roc_auc_score(y_true=y_test, y_score=probas[:, 1]),\n",
    "    acc=accuracy_score(y_true=y_test, y_pred=pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マクロ平均法とマイクロ平均法<a name=\"multi_class\"></a>\n",
    "\n",
    "多クラス分類のための指標。\n",
    "\n",
    "一対全で$k$個のクラスそれぞれの混同行列を作成したとして\n",
    "\n",
    "マクロ平均法は、各クラスで指標を求めてから、それらの平均を最終的な指標として使用する。各クラスを平等に扱う。\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "    PRE_{macro}=\\frac{1}{k}\\left(PRE_1+...+PRE_k\\right) \\nonumber\n",
    "\\end{eqnarray}$\n",
    "\n",
    "マイクロ平均法は、それぞれの分母・分子同士を合計してから、最終的な指標の分母・分子として使用する。各サンプルを平等に扱う。\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "    PRE_{micro}=\\frac{TP_1+...+TP_k}{TP_1+...+TP_k+FP_1+...FP_k} \\nonumber\n",
    "\\end{eqnarray}$\n",
    "\n",
    "scikit-learnで二値分類の指標を使って多クラス分類モデルを評価すると、デフォルトではマクロ平均を正規化(重みづけ)したものが使用される。それ以外の平均化方法を使用したい場合はaverage引数で指定。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
