{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1正則化(Lasso Regression)\n",
    "\n",
    "## L1正則化とは<a name=\"description\"></a>\n",
    "\n",
    "- パラメーターをスパース(sparse, 疎 = 値がない, 0が多い状態)になるように学習\n",
    "- パラメーターが0の特徴は実質的に使われないので、学習と同時に必要な特徴選択を行う\n",
    "- 線形回帰にL1正則化を適用したものをラッソ回帰(Lasso Regression)と呼ぶ\n",
    "\n",
    "## 使用方法<a name=\"example\"></a>\n",
    "\n",
    "### データ準備<a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_sample = 20\n",
    "n_dim = 20\n",
    "n_valid_feature = 5\n",
    "\n",
    "n_feature = 10\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def get_multinomial(x, dim):\n",
    "    return PolynomialFeatures(degree=dim, include_bias=False).fit_transform(x[:, np.newaxis])\n",
    "\n",
    "x = np.linspace(-1, 1, n_sample)\n",
    "X = get_multinomial(x, n_dim)\n",
    "all_features = np.arange(X.shape[1])\n",
    "np.random.shuffle(all_features)\n",
    "valid_features = all_features[:n_valid_feature]\n",
    "coef = np.random.uniform(-1, 1, (n_valid_feature, 1))\n",
    "noise = np.random.normal(0, .1, (n_sample))\n",
    "y = X[:, valid_features].dot(coef).flatten() + noise\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "x_min, x_max = x.min() - .1, x.max() + .1\n",
    "y_min, y_max = y.min() - .1, y.max() + .1\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習<a name=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "\n",
    "linear = LinearRegression().fit(X, y)\n",
    "lasso = Lasso(alpha=0.01, normalize=True)\n",
    "lasso.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可視化<a name=\"visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_coef = np.zeros(n_dim)\n",
    "real_coef[valid_features] = coef[:, 0]\n",
    "for i in range(n_dim):\n",
    "    print('Weight{n:>2}: Real = {coef:>6.3f}, Regularized = {lasso:>6.3f}, Not Regularized = {linear:.3f}'.format(n=i, coef=real_coef[i], lasso=lasso.coef_[i], linear=linear.coef_[i]))\n",
    "\n",
    "sample_x = np.linspace(x_min, x_max, 50)\n",
    "sample_X = get_multinomial(sample_x, n_dim)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "for ax, title, model in zip(axes, ['Not Regularized', 'Regularized'], [linear, lasso]):\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "    ax.scatter(x, y)\n",
    "    ax.plot(sample_x, model.predict(sample_X))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重みの変化<a name=\"weights\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "param = np.logspace(-4, 4, num=n)\n",
    "history = np.zeros((n_dim, n))\n",
    "\n",
    "for i, l in enumerate(param):\n",
    "    history[:, i] = Lasso(alpha=l, normalize=True).fit(X, y).coef_\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for w in history:\n",
    "    plt.plot(param, w)\n",
    "\n",
    "plt.ylabel('weight')\n",
    "plt.xlabel('lambda')\n",
    "plt.xscale('log')\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仕組み<a name=\"mechanism\"></a>\n",
    "\n",
    "### 正則化項<a name=\"definition\"></a>\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "    \\lambda\\|w\\|=\\lambda\\sum_{j=1}^m\\left|\\ w_j\\ \\right| \\nonumber\n",
    "\\end{eqnarray}$\n",
    "\n",
    "### イメージ<a name=\"intuition\"></a>\n",
    "\n",
    "L1正則化項は原点を中心としたひし形状の勾配を持つので、2つの等高線が軸上で交わりやすく、重みが0になりやすい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1, w2 = np.meshgrid(np.linspace(-1, 1, 50), np.linspace(-1, 1, 50))\n",
    "grid = grid = np.c_[w1.ravel(), w2.ravel()]\n",
    "center = (.2, .6)\n",
    "loss = (grid - center) ** 2\n",
    "loss[:, 0] *= .5\n",
    "loss = (loss.sum(axis=1) + (grid[:, 0] - center[0]) * (grid[:, 1] - center[1])).reshape(w1.shape)\n",
    "l1 = np.absolute(grid).sum(axis=1).reshape(w1.shape)\n",
    "objective = loss + l1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "ax1.contour(w1, w2, loss, 20)\n",
    "ax1.set_title('Error')\n",
    "\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "ax2.contour(w1, w2, l1, 20)\n",
    "ax2.set_title('L1 penalty')\n",
    "\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "ax3.contour(w1, w2, objective, 30)\n",
    "ax3.set_title('Total cost')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
