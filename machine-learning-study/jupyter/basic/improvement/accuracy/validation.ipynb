{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バリデーションデータによるハイパーパラメータのチューニング\n",
    "\n",
    "## 検証(validation)<a name=\"description\"></a>\n",
    "\n",
    "- 機械学習ではモデルのパラメータはデータから自動的に学習するものとユーザーが設定するもの(モデルの引数に与える値)があるが、後者を特にハイパーパラメータと呼ぶことがある\n",
    "- ハイパーパラメータをチューニングすることで精度を向上できるが、テストデータでの精度向上を目指してチューニングすると、手動でテストデータの情報をモデルに与え、テストデータに対して過学習を起こす\n",
    "- ハイパーパラメータのチューニングには、データセットを訓練データ・バリデーションデータ・テストデータに分割し、訓練データで学習→バリデーションデータでハイパーパラメータをチューニング→テストデータで汎化能力確認という手順を踏む\n",
    "\n",
    "### 検証データの作成<a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "loader = load_digits()\n",
    "X, y = loader.data, loader.target\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=.4, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=.5, random_state=0)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータのチューニング<a name=\"tuning\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "best = {'score': 0}\n",
    "\n",
    "for gamma in np.logspace(-6, 1, 8):\n",
    "    model = SVC(gamma=gamma, random_state=0).fit(X_train, y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "    if score > best['score']:\n",
    "        best = {'model': model, 'gamma': gamma, 'score': score}\n",
    "print('Best score: {score:.3f} - Test score: {test:.3f} - Best param: gamma={gamma}'.format(\n",
    "    score=best['score'], test=best['model'].score(X_test, y_test), gamma=best['gamma']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差検証(cross-validation)<a name=\"cross-validation\"></a>\n",
    "\n",
    "訓練データをk個に分割し、1個をバリデーションデータ・残りを訓練データとして利用し性能評価、それを全ての組で行って、平均性能をそのパラメータの性能とする。\n",
    "\n",
    "- 訓練データとバリデーションデータの分け方による誤差に強い\n",
    "- 各パラメータについてk回学習を行うので、実行にかかる時間が長くなる\n",
    "\n",
    "完全にランダムにデータを分割すると、各グループでクラスの偏りが発生する可能性があるので、元データのクラス比率を維持しながら分割する層化k分割交差検証(stratified k-fold cross-validation)を用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 検証曲線を表示すると、過学習の様子がわかりやすい(2本のグラフが乖離している部分が過学習)\n",
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_cv, X_test, y_cv,y_test = train_test_split(X, y, test_size=.2, random_state=0, stratify=y)\n",
    "\n",
    "param_range = np.logspace(-6, -1, 6)\n",
    "\n",
    "# validation_curveのcvに整数を設定すると自動的にstratified k-fold cross-validationが適用される\n",
    "train_scores, test_scores = validation_curve(estimator=SVC(random_state=0), X=X_cv, y=y_cv,\n",
    "                                             param_name='gamma', param_range=param_range, cv=10, n_jobs=-1)\n",
    "\n",
    "train_score_mean = train_scores.mean(axis=1)\n",
    "test_score_mean = test_scores.mean(axis=1)\n",
    "\n",
    "print('Best score: {score:.3f} - Best param: gamma={gamma}'.format(\n",
    "    score=test_score_mean.max(), gamma=param_range[np.argmax(test_score_mean)]))\n",
    "\n",
    "plt.plot(param_range, train_score_mean, label='Training')\n",
    "plt.plot(param_range, test_score_mean, label='Validation')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim(.7, 1.01)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GridSearchCVで最適パラメータを自動探索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k=10\n",
    "parameters = [\n",
    "    {'kernel': ['linear'],\n",
    "    'C': np.logspace(-3, 1, 5)},\n",
    "    {'kernel': ['rbf'],\n",
    "    'gamma': np.logspace(-6, 1, 8),\n",
    "    'C': np.logspace(-3, 1, 5)}\n",
    "]\n",
    "\n",
    "# GridSearchCVのcvに整数を設定すると自動的にstratified k-fold cross-validationが適用される\n",
    "clf = GridSearchCV(estimator=SVC(random_state=0), param_grid=parameters, n_jobs=-1, cv=k)\n",
    "clf.fit(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# クロスバリデーションでハイパーパラメータを決定後、全てのデータを使ってパラメータを学習したものがbest_estimatorに入る\n",
    "print('Best score: {score:.3f} - Test score: {test:.3f} - Best param: {params}'.format(\n",
    "    score=clf.best_score_, test=clf.best_estimator_.score(X_test, y_test),\n",
    "    params=', '.join(['{k}={v}'.format(k=k, v=v) for k, v in clf.best_params_.items()])))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
