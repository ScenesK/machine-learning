{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k近傍法(k-nearest neighbor)\n",
    "\n",
    "## k近傍法とは<a name=\"description\"></a>\n",
    "\n",
    "- 最も単純なアルゴリズムの1つ\n",
    "- 特徴空間内で距離的に近い教師データに基づいて分類\n",
    "\n",
    "## 使用例<a name=\"example\"></a>\n",
    "\n",
    "### データ準備<a name=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# 2つの特徴のみ使用\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "cmap = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "margin = .5\n",
    "feature1, feature2 = X[:, 0], X[:, 1]\n",
    "x_min, x_max = feature1.min() - margin, feature1.max() + margin\n",
    "y_min, y_max = feature2.min() - margin, feature2.max() + margin\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "\n",
    "plt.scatter(feature1, feature2, c=y, cmap=cmap)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習<a name=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 15\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の可視化<a name=\"visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "\n",
    "resolution = 300\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution), np.linspace(y_min, y_max, resolution))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap, alpha=.6)\n",
    "\n",
    "plt.scatter(feature1, feature2, c=y, cmap=cmap)\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仕組み<a name=\"mechanism\"></a>\n",
    "\n",
    "- 分類したいデータから特徴空間内での距離の近いk個の教師データの多数決で分類を決定\n",
    "- 訓練データからパラメータを学習せず、訓練データを暗記する怠惰学習(lazy learner)の代表例\n",
    "- 学習にかかるコストはないが、訓練データが増えると特に記憶容量が問題になる\n",
    "- 特徴が増えるに従って、次元の呪いに陥りやすい"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
