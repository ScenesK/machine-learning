{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 外れ値(outlier)\n",
    "\n",
    "他から大きく外れた値があると、予測結果がその値に左右されることがある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.arange(6)[:, np.newaxis]\n",
    "y = - X.flatten()\n",
    "X[-1] = 4\n",
    "y[-1] = 4\n",
    "\n",
    "xx = np.array([X.min() - .5, X.max() + .5])[:, np.newaxis]\n",
    "yy = LinearRegression().fit(X, y).predict(xx)\n",
    "\n",
    "plt.title('Regression with Outlier')\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.plot(xx, yy)\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "外れ値(outlier)の問題は、異常値検出(anomaly detection)と重なる部分が大きい。\n",
    "\n",
    "## 高次元の外れ値<a name=\"high_dimention\"></a>\n",
    "\n",
    "低次元では外れ値に見えても他の特徴と合わせた高次元では(結果に悪影響を与える)外れ値とは言えない場合や、その逆もある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sample = 100\n",
    "n_out = 10\n",
    "n_out_half = n_out // 2\n",
    "margin = 3\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.empty((2, 2, n_sample))\n",
    "X[0, 0] = np.random.uniform(low=0, high=8, size=n_sample)\n",
    "tmp = np.random.uniform(low=11, high=12, size=n_out)\n",
    "X[0, 0, : n_out_half] = tmp[: n_out_half]\n",
    "X[0, 0, - n_out_half :] = tmp[- n_out_half :]\n",
    "X[1, 0] = np.sort(np.random.normal(loc=0, scale=3, size=n_sample))\n",
    "X[:, 1] = X[:, 0] + np.random.normal(size=X[:, 0].shape)\n",
    "X[1, 1, : n_out_half] = X[1, 0, - n_out_half:]\n",
    "X[1, 1, - n_out_half:] = X[1, 0, : n_out_half]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for row, axes_in_row in enumerate(axes):\n",
    "    for col, ax in enumerate(axes_in_row):\n",
    "        x1 = X[row, 0]\n",
    "        x2 = X[row, 1]\n",
    "\n",
    "        include_outlier = (row + col) % 2 == 0\n",
    "\n",
    "        title = '' if include_outlier else 'not '\n",
    "        title += 'likely to be Outlier'\n",
    "        ax.set_title(title)\n",
    "\n",
    "        id_in = np.arange(n_out_half, n_sample - n_out_half, dtype=np.uint)\n",
    "        id_out = np.concatenate((np.arange(n_out_half, dtype=np.uint), np.arange(n_out_half, dtype=np.uint) + n_sample - n_out_half))\n",
    "        color = 'r' if include_outlier else 'b'\n",
    "        if col == 0:\n",
    "            r = (X[row, 0].min(), X[row, 0].max())\n",
    "\n",
    "            if not include_outlier:\n",
    "                ax.hist(x1, color=color, range=r)\n",
    "            else:\n",
    "                ax.hist(x1[id_in], color='b', range=r)\n",
    "                ax.hist(x1[id_out], color=color, range=r)\n",
    "        else:\n",
    "            ax.scatter(x1[id_in], x2[id_in], color='b')\n",
    "            ax.scatter(x1[id_out], x2[id_out], color=color)\n",
    "            lin_min, lin_max = x1.min() - margin, x1.max() + margin\n",
    "\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 外れ値が生じる原因<a name=\"cause\"></a>\n",
    "\n",
    "外れ値が生じる原因はいろいろ考えられる。\n",
    "\n",
    "- センサーの故障\n",
    "- データ入力ミス\n",
    "- 表計算ソフトの集計行混入\n",
    "- 特異なイベントの発生(近くでイベントが行われた等)\n",
    "\n",
    "外れ値の生じた原因に応じて、取り扱いを考える必要がある。外れ値が起こるべきでない異常によって生じた場合は外れ値をデータから取り除き、外れ値が予測を改善しそうな情報を含む場合はそれを捉える特徴を新たに設計することで、性能を向上させられる。\n",
    "\n",
    "## 外れ値の除去<a name=\"removal\"></a>\n",
    "\n",
    "極端に誤差・残差の大きいものや、上位10%を除去する。やりすぎると過学習しやすくなるので慎重に行う。また、外れ値がセンサーの故障などで定期的に発生する可能性がある場合は、異常値として検出できるようにしておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.sort(np.random.uniform(low=0, high=10, size=100))\n",
    "y = X + np.random.normal(size=X.shape)\n",
    "y[:5], y[-5:] = X[-5:], X[:5]\n",
    "\n",
    "regr = LinearRegression().fit(X[:, np.newaxis], y)\n",
    "pred = regr.predict(X[:, np.newaxis])\n",
    "residual = y - pred\n",
    "id_out = np.argsort(np.abs(residual))[-10:]\n",
    "\n",
    "print('Index of highest 10% residual: {res}'.format(res=id_out))\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "plt.scatter(pred, residual, color='b')\n",
    "plt.scatter(pred[id_out], residual[id_out], color='r')\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
