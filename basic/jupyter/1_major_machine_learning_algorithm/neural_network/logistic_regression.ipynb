{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰(Logistic Regression)\n",
    "\n",
    "## ロジスティック回帰とは\n",
    "\n",
    "- 名前に回帰とついているが、分類のアルゴリズム\n",
    "- 単純パーセプトロンの活性化関数をシグモイド関数(2クラスロジスティック回帰)やソフトマックス関数(多クラスロジスティック回帰)にしたもの\n",
    "- ここでは多クラスロジスティック回帰を扱う(2クラスロジスティック回帰は[単純パーセプトロン](simple_perceptron.ipynb)を参照)\n",
    "\n",
    "### scikit-learnの実装\n",
    "\n",
    "- scikit-learnのlinear_model.LogisticRegressionは、必ず正則化項 (penalty)が入る(正則化不要ならOne vs Restになるが、linear_model.Perceptronを使用)\n",
    "\n",
    "## 使用方法\n",
    "\n",
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, centers=3, random_state=0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sk_clf = LogisticRegression(solver='sag', max_iter=100, random_state=0, multi_class='multinomial', n_jobs=-1)\n",
    "sk_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "keras_clf = Sequential()\n",
    "keras_clf.add(Dense(output_dim=3, input_dim=2))\n",
    "keras_clf.add(Activation('softmax'))\n",
    "keras_clf.compile(optimizer=SGD(lr=0.01), loss='categorical_crossentropy')\n",
    "keras_clf.fit(X, to_categorical(y, nb_classes=3), batch_size=100, nb_epoch=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.datasets.tuple_dataset import TupleDataset\n",
    "from chainer.iterators import SerialIterator\n",
    "from chainer.training import StandardUpdater, Trainer\n",
    "\n",
    "class LogisticRegression(chainer.Chain):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__(\n",
    "            l1 = L.Linear(2, 3)\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "train_data = TupleDataset(X, y)\n",
    "ch_clf = L.Classifier(LogisticRegression())\n",
    "ch_clf.compute_accuracy = False\n",
    "optimizer = chainer.optimizers.SGD()\n",
    "optimizer.setup(ch_clf)\n",
    "train_iter = SerialIterator(train_data, 100)\n",
    "updater = StandardUpdater(train_iter, optimizer, device=-1)\n",
    "trainer = Trainer(updater, (1000, 'iteration'))\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "learn = tf.contrib.learn\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "def model(x, y):\n",
    "    y = slim.one_hot_encoding(y, 3)\n",
    "    logits = slim.fully_connected(x, 3, activation_fn=None)\n",
    "    loss = slim.losses.softmax_cross_entropy(logits, y)\n",
    "    train_op = slim.optimize_loss(loss, slim.get_global_step(), learning_rate=0.01, optimizer='SGD')\n",
    "    prob = slim.softmax(logits)\n",
    "\n",
    "    return {'class': tf.argmax(prob, 1), 'prob': prob}, loss, train_op\n",
    "\n",
    "tf_clf = learn.SKCompat(learn.Estimator(model_fn=model))\n",
    "tf_clf.fit(x=X, y=y, steps=1000, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "resolution = 200\n",
    "linewidth = min(x_max - x_min, y_max - y_min) / resolution\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, resolution), np.linspace(y_min, y_max, resolution))\n",
    "xx, yy = xx.astype(np.float32), yy.astype(np.float32)\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# scikit-learn\n",
    "probas = sk_clf.predict_proba(grid)\n",
    "# Keras\n",
    "# probas = keras_clf.predict_proba(grid, verbose=0)\n",
    "# Chainer\n",
    "# probas = F.softmax(ch_clf.predictor(grid)).data\n",
    "# TensorFlow\n",
    "# probas = tf_clf.predict(grid)['prob']\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.scatter(xx.ravel(), yy.ravel(), c=probas, marker='.', alpha=0.6, linewidths=linewidth)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=ListedColormap(['#FF0000', '#00FF00', '#0000FF']))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
